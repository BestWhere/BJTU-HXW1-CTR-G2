{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 线上分数：0.81\n",
    "\n",
    "\n",
    "# ----------------环境配置----------------\n",
    "# 安装相关依赖库 如果是windows系统，cmd命令框中输入pip安装，参考上述环境配置\n",
    "# !pip install sklearn\n",
    "# !pip install pandas\n",
    "# !pip install catboost\n",
    "# --------------------------------------\n",
    "import catboost\n",
    "# ----------------导入库-----------------\n",
    "# 数据探索模块使用第三方库\n",
    "from pandas.core.frame import DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import *\n",
    "# 核心模型使用第三方库\n",
    "# from catboost import CatBoostClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "# 交叉验证所使用的第三方库\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "# 评估指标所使用的的第三方库\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss\n",
    "# 忽略报警所使用的第三方库\n",
    "import warnings\n",
    "\n",
    "# warnings.filterwarnings('ignore')\n",
    "import random\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) # 禁止hash随机化\n",
    "set_seed(2022)\n",
    "# --------------------------------------\n",
    "\n",
    "# ----------------数据预处理-------------\n",
    "# 读取训练数据和测试数据\n",
    "# 读取训练数据和测试数据\n",
    "train_data_ads = pd.read_csv('../dataset/train.csv')\n",
    "train_data_feeds = pd.read_csv('../dataset/train_feeds.csv')\n",
    "\n",
    "test_data_ads = pd.read_csv('../dataset/final_test.csv')\n",
    "test_data_feeds = pd.read_csv('../dataset/test_feeds.csv')\n",
    "\n",
    "\n",
    "# 合并数据\n",
    "train_data_ads['istest'] = 0\n",
    "test_data_ads['istest'] = 1\n",
    "data_ads = pd.concat([train_data_ads, test_data_ads], axis=0, ignore_index=True)\n",
    "\n",
    "train_data_feeds['istest'] = 0\n",
    "test_data_feeds['istest'] = 1\n",
    "data_feeds = pd.concat([train_data_feeds, test_data_feeds], axis=0, ignore_index=True)\n",
    "\n",
    "del train_data_ads, test_data_ads, train_data_feeds, test_data_feeds\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# ----------------特征工程---------------\n",
    "# 包含自然数编码、特征提取和内存压缩三部分内容。\n",
    "# 1、自然数编码\n",
    "def label_encode(series, series2):\n",
    "    unique = list(series.unique())\n",
    "    return series2.map(dict(zip(\n",
    "        unique, range(series.nunique())\n",
    "    )))\n",
    "\n",
    "\n",
    "for col in ['ad_click_list_v001', 'ad_click_list_v002', 'ad_click_list_v003', 'ad_close_list_v001',\n",
    "            'ad_close_list_v002', 'ad_close_list_v003', 'u_newsCatInterestsST']:\n",
    "    data_ads[col] = label_encode(data_ads[col], data_ads[col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2、特征提取\n",
    "\n",
    "data_feeds特征构建\n",
    "\n",
    "特征提取部分围绕着data_feeds进行构建（添加源域信息）\n",
    "\n",
    "主要是nunique属性数统计和mean均值统计。\n",
    "\n",
    "由于是baseline方案，所以整体的提取比较粗暴，大家还是有很多的优化空间。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nunique属性数统计特征 Starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:44<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nunique属性数统计特征 Ending...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# -------------------------------1. nunique属性数统计特征-------------------------------------------\n",
    "print('nunique属性数统计特征 Starting...')\n",
    "cols = [f for f in data_feeds.columns if f not in ['label', 'istest', 'u_userId']]\n",
    "for col in tqdm(cols):\n",
    "    tmp = data_feeds.groupby(['u_userId'])[col].nunique().reset_index()\n",
    "    tmp.columns = ['user_id', col + '_feeds_nuni']\n",
    "    data_ads = data_ads.merge(tmp, on='user_id', how='left')\n",
    "print('nunique属性数统计特征 Ending...')\n",
    "# -----------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean均值统计特征 Starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:21<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean均值统计特征 Ending...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# -------------------------------2. mean均值统计特征------------------------------------------------\n",
    "print('mean均值统计特征 Starting...')\n",
    "cols = [f for f in data_feeds.columns if\n",
    "        f not in ['istest', 'u_userId', 'u_newsCatInterests', 'u_newsCatDislike', 'u_newsCatInterestsST',\n",
    "                  'u_click_ca2_news', 'i_docId', 'i_s_sourceId', 'i_entities']]\n",
    "for col in tqdm(cols):\n",
    "    tmp = data_feeds.groupby(['u_userId'])[col].mean().reset_index()\n",
    "    tmp.columns = ['user_id', col + '_feeds_mean']\n",
    "    data_ads = data_ads.merge(tmp, on='user_id', how='left')\n",
    "print('mean均值统计特征 Ending...')\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# -------------------------------3. 穿越特征------------------------------------------------\n",
    "# print('穿越特征 Starting...')\n",
    "# 2022 05 22 14 30\n",
    "data_ads['month'] = data_ads['pt_d'].apply(lambda x: int(str(x)[4:6]))  # 左闭右开\n",
    "data_ads['day'] = data_ads['pt_d'].apply(lambda x: int(str(x)[6:8]))\n",
    "# data_ads['hour'] = data_ads['pt_d'].apply(lambda x: int(str(x)[8:10]))\n",
    "# data_ads['minu'] = data_ads['pt_d'].apply(lambda x: int(str(x)[10:12]))\n",
    "# data_ads['date'] = data_ads['day']*1440 + data_ads['hour']*60 + data_ads['minu']\n",
    "data_ads['date'] = data_ads['month']*30+data_ads['day']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id make feature\n",
      "task_id make feature\n",
      "adv_id make feature\n",
      "user_id_adv_id make feature\n",
      "user_id_task_id make feature\n",
      "user_id_creat_type_cd make feature\n",
      "user_id_adv_prim_id make feature\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(-gap)\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(+gap)\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(-gap)\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(+gap)\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(-gap)\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(+gap)\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id_inter_type_cd make feature\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(-gap)\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(+gap)\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(-gap)\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(+gap)\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(-gap)\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(+gap)\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id_slot_id make feature\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(-gap)\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(+gap)\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(-gap)\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(+gap)\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(-gap)\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(+gap)\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id_site_id make feature\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(-gap)\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(+gap)\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(-gap)\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(+gap)\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(-gap)\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(+gap)\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id_spread_app_id make feature\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(-gap)\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(+gap)\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(-gap)\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(+gap)\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(-gap)\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(+gap)\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_next_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_{}_{}_diff_last_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
      "C:\\Users\\76678\\AppData\\Local\\Temp\\ipykernel_17212\\847139277.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_date_feature(data, gap_list=[1], col=['user_id']):\n",
    "\n",
    "    for gap in gap_list:\n",
    "\n",
    "        # 后面时间-当前时间\n",
    "        data['ts_{}_{}_diff_next'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(-gap)\n",
    "        data['ts_{}_{}_diff_next'.format('_'.join(col), gap)] = data['ts_{}_{}_diff_next'.format('_'.join(col), gap)] - \\\n",
    "                                                                data['date']\n",
    "\n",
    "        # 前面时间-当前时间\n",
    "        data['ts_{}_{}_diff_last'.format('_'.join(col), gap)] = data.groupby(col)['date'].shift(+gap)\n",
    "        data['ts_{}_{}_diff_last'.format('_'.join(col), gap)] = data['date'] - data[\n",
    "            'ts_{}_{}_diff_last'.format('_'.join(col), gap)]\n",
    "\n",
    "        # 统计不为nan的值，做差前有曝光，做差后就不会为nan。\n",
    "        data['ts_{}_{}_diff_next_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
    "            'ts_{}_{}_diff_next'.format('_'.join(col), gap)].transform('count')\n",
    "        data['ts_{}_{}_diff_last_count'.format('_'.join(col), gap)] = data.groupby(col)[\n",
    "            'ts_{}_{}_diff_last'.format('_'.join(col), gap)].transform('count')\n",
    "\n",
    "        # 统计时间差的平均值\n",
    "        data['ts_{}_{}_diff_next_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
    "            'ts_{}_{}_diff_next'.format('_'.join(col), gap)].transform('mean')\n",
    "        data['ts_{}_{}_diff_last_mean'.format('_'.join(col), gap)] = data.groupby(col)[\n",
    "            'ts_{}_{}_diff_last'.format('_'.join(col), gap)].transform('mean')\n",
    "\n",
    "        # 统计时间差的最大值\n",
    "        data['ts_{}_{}_diff_next_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
    "            'ts_{}_{}_diff_next'.format('_'.join(col), gap)].transform('max')\n",
    "        data['ts_{}_{}_diff_last_max'.format('_'.join(col), gap)] = data.groupby(col)[\n",
    "            'ts_{}_{}_diff_last'.format('_'.join(col), gap)].transform('max')\n",
    "\n",
    "        # 统计时间差的最小值\n",
    "        data['ts_{}_{}_diff_next_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
    "            'ts_{}_{}_diff_next'.format('_'.join(col), gap)].transform('min')\n",
    "        data['ts_{}_{}_diff_last_min'.format('_'.join(col), gap)] = data.groupby(col)[\n",
    "            'ts_{}_{}_diff_last'.format('_'.join(col), gap)].transform('min')\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_diff_date(data, gap_list=[1, 2, 3], col=['user_id'], con_list=[1], f='next'):\n",
    "    for gap in gap_list:\n",
    "        for con in con_list:\n",
    "            data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
    "                'ts_{}_{}_diff_{}'.format('_'.join(col), con, f)].shift(-gap)\n",
    "            data['ts_s_{}_{}_{}_next_{}'.format(f, '_'.join(col), gap, con)] = data['ts_s_{}_{}_{}_next_{}'.format(f,\n",
    "                                                                                                                   '_'.join(\n",
    "                                                                                                                       col),\n",
    "                                                                                                                   gap,\n",
    "                                                                                                                   con)] - \\\n",
    "                                                                               data['ts_{}_{}_diff_{}'.format(\n",
    "                                                                                   '_'.join(col), con, f)]\n",
    "\n",
    "            data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data.groupby(col)[\n",
    "                'ts_{}_{}_diff_{}'.format('_'.join(col), con, f)].shift(+gap)\n",
    "            data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)] = data['ts_{}_{}_diff_{}'.format(\n",
    "                '_'.join(col), con, f)] - data['ts_s_{}_{}_{}_last_{}'.format(f, '_'.join(col), gap, con)]\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "for col in [\n",
    "    ['user_id'], ['task_id'], ['adv_id'],\n",
    "    ['user_id', 'adv_id'], ['user_id', 'task_id'], ['user_id', 'creat_type_cd'],\n",
    "    ['user_id', 'adv_prim_id'], ['user_id', 'inter_type_cd'], ['user_id', 'slot_id'],\n",
    "    ['user_id', 'site_id'], ['user_id', 'spread_app_id']\n",
    "]:\n",
    "    print('_'.join(col), 'make', 'feature')\n",
    "    data_ads = get_date_feature(data_ads, gap_list=[1, 2, 3], col=col)\n",
    "    data_ads = get_diff_date(data_ads, gap_list=[1, 2, 3], col=col, con_list=[1], f='next')\n",
    "    data_ads = get_diff_date(data_ads, gap_list=[1, 2, 3], col=col, con_list=[1], f='last')\n",
    "\n",
    "\n",
    "# print('穿越特征 Ending...')\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 3049.07 Mb (75.1% reduction)\n",
      "************************************ 1 2022************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\76678\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\76678\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\data.py:312: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "C:\\Users\\76678\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\data.py:314: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  elif is_categorical_dtype(dtype) and enable_categorical:\n",
      "C:\\Users\\76678\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\data.py:345: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype)\n",
      "C:\\Users\\76678\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\data.py:336: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "C:\\Users\\76678\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\data.py:440: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n",
      "C:\\Users\\76678\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\data.py:312: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "C:\\Users\\76678\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\data.py:314: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  elif is_categorical_dtype(dtype) and enable_categorical:\n",
      "C:\\Users\\76678\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\data.py:345: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype)\n",
      "C:\\Users\\76678\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\data.py:336: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "C:\\Users\\76678\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\data.py:440: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:54:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:767: \n",
      "Parameters: { \"random_seed\" } are not used.\n",
      "\n",
      "[0]\tvalidation_0-auc:0.70016\n",
      "[1]\tvalidation_0-auc:0.71032\n",
      "[2]\tvalidation_0-auc:0.71202\n",
      "[3]\tvalidation_0-auc:0.71177\n",
      "[4]\tvalidation_0-auc:0.71483\n",
      "[5]\tvalidation_0-auc:0.71614\n",
      "[6]\tvalidation_0-auc:0.71662\n",
      "[7]\tvalidation_0-auc:0.72097\n",
      "[8]\tvalidation_0-auc:0.72592\n",
      "[9]\tvalidation_0-auc:0.72622\n",
      "[10]\tvalidation_0-auc:0.72838\n",
      "[11]\tvalidation_0-auc:0.73066\n",
      "[12]\tvalidation_0-auc:0.73507\n",
      "[13]\tvalidation_0-auc:0.73826\n",
      "[14]\tvalidation_0-auc:0.74108\n",
      "[15]\tvalidation_0-auc:0.74267\n",
      "[16]\tvalidation_0-auc:0.74400\n",
      "[17]\tvalidation_0-auc:0.74663\n",
      "[18]\tvalidation_0-auc:0.74926\n",
      "[19]\tvalidation_0-auc:0.75166\n",
      "[20]\tvalidation_0-auc:0.75337\n",
      "[21]\tvalidation_0-auc:0.75561\n",
      "[22]\tvalidation_0-auc:0.75728\n",
      "[23]\tvalidation_0-auc:0.75916\n",
      "[24]\tvalidation_0-auc:0.76170\n",
      "[25]\tvalidation_0-auc:0.76267\n",
      "[26]\tvalidation_0-auc:0.76288\n",
      "[27]\tvalidation_0-auc:0.76358\n",
      "[28]\tvalidation_0-auc:0.76477\n",
      "[29]\tvalidation_0-auc:0.76593\n",
      "[30]\tvalidation_0-auc:0.76523\n",
      "[31]\tvalidation_0-auc:0.76839\n",
      "[32]\tvalidation_0-auc:0.76916\n",
      "[33]\tvalidation_0-auc:0.76927\n",
      "[34]\tvalidation_0-auc:0.76974\n",
      "[35]\tvalidation_0-auc:0.77004\n",
      "[36]\tvalidation_0-auc:0.77036\n",
      "[37]\tvalidation_0-auc:0.77023\n",
      "[38]\tvalidation_0-auc:0.77045\n",
      "[39]\tvalidation_0-auc:0.77080\n",
      "[40]\tvalidation_0-auc:0.77099\n",
      "[41]\tvalidation_0-auc:0.77187\n",
      "[42]\tvalidation_0-auc:0.77213\n",
      "[43]\tvalidation_0-auc:0.77189\n",
      "[44]\tvalidation_0-auc:0.77298\n",
      "[45]\tvalidation_0-auc:0.77288\n",
      "[46]\tvalidation_0-auc:0.77336\n",
      "[47]\tvalidation_0-auc:0.77326\n",
      "[48]\tvalidation_0-auc:0.77371\n",
      "[49]\tvalidation_0-auc:0.77418\n",
      "[50]\tvalidation_0-auc:0.77471\n",
      "[51]\tvalidation_0-auc:0.77449\n",
      "[52]\tvalidation_0-auc:0.77445\n",
      "[53]\tvalidation_0-auc:0.77453\n",
      "[54]\tvalidation_0-auc:0.77466\n",
      "[55]\tvalidation_0-auc:0.77462\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\机器学习\\大作业\\baseline_xgboost\\xgboost.ipynb 单元格 7\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E4%BD%9C%E4%B8%9A/baseline_xgboost/xgboost.ipynb#W6sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_score_std:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m clf_name, np\u001b[39m.\u001b[39mstd(cv_scores))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E4%BD%9C%E4%B8%9A/baseline_xgboost/xgboost.ipynb#W6sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m train, test\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E4%BD%9C%E4%B8%9A/baseline_xgboost/xgboost.ipynb#W6sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m cat_train, cat_test \u001b[39m=\u001b[39m cv_model(XGBClassifier, x_train, y_train, x_test, \u001b[39m\"\u001b[39;49m\u001b[39mxgb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E4%BD%9C%E4%B8%9A/baseline_xgboost/xgboost.ipynb#W6sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m \u001b[39m# --------------------------------------\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E4%BD%9C%E4%B8%9A/baseline_xgboost/xgboost.ipynb#W6sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E4%BD%9C%E4%B8%9A/baseline_xgboost/xgboost.ipynb#W6sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m \u001b[39m# ----------------结果保存---------------\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E4%BD%9C%E4%B8%9A/baseline_xgboost/xgboost.ipynb#W6sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m test_pred \u001b[39m=\u001b[39m cat_test[:, \u001b[39m1\u001b[39m]\n",
      "\u001b[1;32md:\\机器学习\\大作业\\baseline_xgboost\\xgboost.ipynb 单元格 7\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E4%BD%9C%E4%B8%9A/baseline_xgboost/xgboost.ipynb#W6sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m params \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mrandom_seed\u001b[39m\u001b[39m'\u001b[39m: seed}\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E4%BD%9C%E4%B8%9A/baseline_xgboost/xgboost.ipynb#W6sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m model \u001b[39m=\u001b[39m clf(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E4%BD%9C%E4%B8%9A/baseline_xgboost/xgboost.ipynb#W6sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(trn_x, trn_y, eval_set\u001b[39m=\u001b[39;49m[(val_x, val_y)],\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E4%BD%9C%E4%B8%9A/baseline_xgboost/xgboost.ipynb#W6sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m           verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, eval_metric\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mauc\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E4%BD%9C%E4%B8%9A/baseline_xgboost/xgboost.ipynb#W6sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m val_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict_proba(val_x)[:, \u001b[39m1\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E4%BD%9C%E4%B8%9A/baseline_xgboost/xgboost.ipynb#W6sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m test_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict_proba(test_x)[:, \u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:1490\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1462\u001b[0m (\n\u001b[0;32m   1463\u001b[0m     model,\n\u001b[0;32m   1464\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1470\u001b[0m )\n\u001b[0;32m   1471\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1472\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[0;32m   1473\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1487\u001b[0m     feature_types\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_types,\n\u001b[0;32m   1488\u001b[0m )\n\u001b[1;32m-> 1490\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m   1491\u001b[0m     params,\n\u001b[0;32m   1492\u001b[0m     train_dmatrix,\n\u001b[0;32m   1493\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[0;32m   1494\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[0;32m   1495\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[0;32m   1496\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[0;32m   1497\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[0;32m   1498\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[0;32m   1499\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   1500\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m   1501\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1502\u001b[0m )\n\u001b[0;32m   1504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[0;32m   1505\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[0;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[0;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[0;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[0;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# 3、内存压缩\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (\n",
    "                start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "\n",
    "# 压缩使用内存\n",
    "# 由于数据比较大，所以合理的压缩内存节省空间尤为的重要\n",
    "# 使用reduce_mem_usage函数可以压缩近70%的内存占有。\n",
    "data_ads = reduce_mem_usage(data_ads)\n",
    "# Mem. usage decreased to 3351.47 Mb (79.3% reduction)\n",
    "# --------------------------------------\n",
    "\n",
    "# ----------------数据集划分-------------\n",
    "# 划分训练集和测试集\n",
    "cols = [f for f in data_ads.columns if f not in ['label', 'istest']]\n",
    "x_train = data_ads[data_ads.istest == 0][cols]\n",
    "x_test = data_ads[data_ads.istest == 1][cols]\n",
    "\n",
    "y_train = data_ads[data_ads.istest == 0]['label']\n",
    "\n",
    "del data_ads, data_feeds\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# --------------------------------------\n",
    "\n",
    "# ----------------训练模型---------------\n",
    "def cv_model(clf, train_x, train_y, test_x, clf_name, seed=2022):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "    train = np.zeros(train_x.shape[0])\n",
    "    test = np.zeros(test_x.shape[0])\n",
    "\n",
    "    cv_scores = []\n",
    "\n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(train_x, train_y)):\n",
    "        print('************************************ {} {}************************************'.format(str(i + 1),\n",
    "                                                                                                      str(seed)))\n",
    "        trn_x, trn_y, val_x, val_y = train_x.iloc[train_index], train_y[train_index], train_x.iloc[valid_index], \\\n",
    "                                     train_y[valid_index]\n",
    "\n",
    "        params = {'random_seed': seed}\n",
    "\n",
    "        model = clf(**params)\n",
    "        model.fit(trn_x, trn_y, eval_set=[(val_x, val_y)],\n",
    "                  verbose=1, eval_metric='auc')\n",
    "\n",
    "        val_pred = model.predict_proba(val_x)[:, 1]\n",
    "        test_pred = model.predict_proba(test_x)[:, 1]\n",
    "\n",
    "        train[valid_index] = val_pred\n",
    "        test += test_pred / kf.n_splits\n",
    "        cv_scores.append(roc_auc_score(val_y, val_pred))\n",
    "\n",
    "        print(cv_scores)\n",
    "\n",
    "    print(\"%s_score_list:\" % clf_name, cv_scores)\n",
    "    print(\"%s_score_mean:\" % clf_name, np.mean(cv_scores))\n",
    "    print(\"%s_score_std:\" % clf_name, np.std(cv_scores))\n",
    "    return train, test\n",
    "\n",
    "\n",
    "cat_train, cat_test = cv_model(XGBClassifier, x_train, y_train, x_test, \"xgb\")\n",
    "# --------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cat_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\机器学习\\大作业\\baseline_xgboost\\xgboost.ipynb 单元格 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E4%BD%9C%E4%B8%9A/baseline_xgboost/xgboost.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# ----------------结果保存---------------\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E4%BD%9C%E4%B8%9A/baseline_xgboost/xgboost.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m test_pred \u001b[39m=\u001b[39m cat_test\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E4%BD%9C%E4%B8%9A/baseline_xgboost/xgboost.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# x_test['pctr'] = cat_test\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E4%BD%9C%E4%B8%9A/baseline_xgboost/xgboost.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# x_test[['log_id', 'pctr']].to_csv('submission_xgb.csv', index=False)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E4%BD%9C%E4%B8%9A/baseline_xgboost/xgboost.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m df \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mpctr\u001b[39m\u001b[39m'\u001b[39m: test_pred}\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cat_test' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------------结果保存---------------\n",
    "test_pred = cat_test\n",
    "# x_test['pctr'] = cat_test\n",
    "# x_test[['log_id', 'pctr']].to_csv('submission_xgb.csv', index=False)\n",
    "df = {'pctr': test_pred}\n",
    "df = DataFrame(df)\n",
    "df = df.reset_index()\n",
    "df.columns = ['id', 'pctr']\n",
    "df.to_csv('./submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
